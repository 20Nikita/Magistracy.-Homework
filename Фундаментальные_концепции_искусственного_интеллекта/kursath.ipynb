{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e641de91-8305-4708-aabe-dfd2851e8a32",
   "metadata": {},
   "source": [
    "# 300W_LP [Домашняя страница](http://www.cbsr.ia.ac.cn/users/xiangyuzhu/projects/3DDFA/main.htm?utm_source=www.tensorflow.org&utm_medium=referral)\n",
    "## Набор данных 300W-LP (Large Pose) основан на исходных изображениях 300W, <br /> расширенных алгоритмическими методами с 600 до 61 тыс. изображений. \n",
    "\n",
    "<img src=\"https://mlv4xkdrf2yq.i.optimole.com/cb:0l1_~a759/w:850/h:699/q:mauto/https://datagen.tech/app/uploads/2022/06/image1-2.png\">\n",
    "\n",
    "#### 300-W — это набор данных изображений лиц. Он содержит 300 изображений в помещении и 300 изображений на открытом воздухе с человеческими лицами, снятыми в дикой природе. Он охватывает разные лица, выражения лица, условия освещения, позы и размеры лица. Изображения были загружены с google.com с использованием поисковых запросов «вечеринка», «встреча», «протест» и «знаменитость». По сравнению с аналогичными наборами данных, 300W имеет более высокую долю частично закрытых изображений и необычные выражения лиц, такие как «удивление» и «крик». Изображения были аннотированы 68 точечными маркерами с использованием полуавтоматического метода. Размер изображений составляет от 48 КБ до 2 МБ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee0373a0-4137-45ea-a686-e33896ccbfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abb8da1-3144-4a19-861e-dea61e87fe1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "[300W-LP]: https://drive.google.com/file/d/0B7OEHD3T4eCkVGs0TkhUWFN6N1k/view?usp=sharing&resourcekey=0-WT5tO4TOCbNZY6r6z6WmOA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ee2d7b8-0362-44e7-987e-b1f8e84126c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "96b9ca36-fad0-470e-8793-556fcbbc431b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ypr_from_mat(mat_path):\n",
    "    # Get yaw, pitch, roll from .mat annotation.\n",
    "    # They are in radians\n",
    "    mat = sio.loadmat(mat_path)\n",
    "    print(mat.keys())\n",
    "    # [pitch yaw roll tdx tdy tdz scale_factor]\n",
    "    pre_pose_params = mat['Pose_Para'][0]\n",
    "    # Get [pitch, yaw, roll]\n",
    "    pose_params = pre_pose_params[:3]\n",
    "    return pose_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "21e94183-32ba-46d8-8eb6-f69280c5df56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['__header__', '__version__', '__globals__', 'pt2d', 'roi', 'Illum_Para', 'Color_Para', 'Tex_Para', 'Shape_Para', 'Exp_Para', 'Pose_Para'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.08791836,  0.00418041,  0.0265818 ], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ypr_from_mat(\"data/AFW/AFW_1051618982_1_0.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3385d8-dbc6-4844-b2c2-1177ffcf20e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def get_ypr_from_mat(mat_path):\n",
    "    # Get yaw, pitch, roll from .mat annotation.\n",
    "    # They are in radians\n",
    "    mat = sio.loadmat(mat_path)\n",
    "    # [pitch yaw roll tdx tdy tdz scale_factor]\n",
    "    pre_pose_params = mat['Pose_Para'][0]\n",
    "    # Get [pitch, yaw, roll]\n",
    "    pose_params = pre_pose_params[:3]\n",
    "    return pose_params\n",
    "\n",
    "\n",
    "dirr = \"300W_LP\"\n",
    "f = open(\"300W_LP_val_annotation.txt\", \"w\")\n",
    "f.write(\"snp,x,y,z\")\n",
    "papki = os.listdir(dirr)\n",
    "k=0\n",
    "for i in range(len(papki)):\n",
    "    file = os.listdir(dirr + \"/\" + papki[i])\n",
    "    for j in range(len(file)):\n",
    "        t = file[j].split(\".\")\n",
    "        try:\n",
    "            if t[1] == \"mat\":\n",
    "                k+=1\n",
    "                pose = get_ypr_from_mat(dirr + \"/\" + papki[i] + \"/\" + file[j])\n",
    "                # And convert to degrees.\n",
    "                pitch = pose[0] * 180 / np.pi\n",
    "                yaw = pose[1] * 180 / np.pi\n",
    "                roll = pose[2] * 180 / np.pi\n",
    "                f.write(papki[i] + \"/\" + t[0] + '.jpg' + \",\" + str(yaw) + \",\" + str(pitch) + \",\" + str(roll))\n",
    "        except:\n",
    "            print(t)\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a6dfc0d-ed40-4034-a1af-d1e0702696e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "# Copyright 2022 The TensorFlow Datasets Authors.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "\"\"\"300W-LP Dataset.\"\"\"\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets.public_api as tfds\n",
    "\n",
    "_DATASET_URL = \"https://drive.google.com/uc?export=download&id=0B7OEHD3T4eCkVGs0TkhUWFN6N1k\"\n",
    "\n",
    "_PROJECT_URL = \"http://www.cbsr.ia.ac.cn/users/xiangyuzhu/projects/3DDFA/main.htm\"\n",
    "\n",
    "\n",
    "class Builder(tfds.core.GeneratorBasedBuilder):\n",
    "  \"\"\"300W-LP dataset.\"\"\"\n",
    "\n",
    "  VERSION = tfds.core.Version(\"1.0.0\")\n",
    "\n",
    "  def _info(self):\n",
    "    return self.dataset_info_from_configs(\n",
    "        features=tfds.features.FeaturesDict({\n",
    "            \"image\":\n",
    "                tfds.features.Image(\n",
    "                    shape=(450, 450, 3), encoding_format=\"jpeg\"),\n",
    "            \"landmarks_origin\":\n",
    "                tfds.features.Tensor(shape=(68, 2), dtype=np.float32),\n",
    "            \"landmarks_2d\":\n",
    "                tfds.features.Tensor(shape=(68, 2), dtype=np.float32),\n",
    "            \"landmarks_3d\":\n",
    "                tfds.features.Tensor(shape=(68, 2), dtype=np.float32),\n",
    "            \"roi\":\n",
    "                tfds.features.Tensor(shape=(4,), dtype=np.float32),\n",
    "            \"illum_params\":\n",
    "                tfds.features.Tensor(shape=(10,), dtype=np.float32),\n",
    "            \"color_params\":\n",
    "                tfds.features.Tensor(shape=(7,), dtype=np.float32),\n",
    "            \"tex_params\":\n",
    "                tfds.features.Tensor(shape=(199,), dtype=np.float32),\n",
    "            \"shape_params\":\n",
    "                tfds.features.Tensor(shape=(199,), dtype=np.float32),\n",
    "            \"exp_params\":\n",
    "                tfds.features.Tensor(shape=(29,), dtype=np.float32),\n",
    "            \"pose_params\":\n",
    "                tfds.features.Tensor(shape=(7,), dtype=np.float32)\n",
    "        }),\n",
    "        homepage=_PROJECT_URL,\n",
    "    )\n",
    "\n",
    "  def _split_generators(self, dl_manager):\n",
    "    \"\"\"Returns SplitGenerators.\"\"\"\n",
    "    extracted_path = dl_manager.download_and_extract(_DATASET_URL)\n",
    "    return [\n",
    "        tfds.core.SplitGenerator(\n",
    "            name=tfds.Split.TRAIN,\n",
    "            gen_kwargs={\n",
    "                \"image_dir_path\": os.path.join(extracted_path, \"300W_LP\"),\n",
    "            }),\n",
    "    ]\n",
    "\n",
    "  def _generate_examples(self, image_dir_path):\n",
    "    \"\"\"Yields examples.\"\"\"\n",
    "    image_files = tf.io.gfile.glob(\n",
    "        pattern=os.path.join(image_dir_path, \"[!Code]*[!_Flip]/[!_]*.jpg\"))\n",
    "    label_files = [s.replace(\"jpg\", \"mat\") for s in image_files]\n",
    "    landmark_files = [\n",
    "        s.replace(\"300W_LP\", \"300W_LP/landmarks\").replace(\".jpg\", \"_pts.mat\")\n",
    "        for s in image_files\n",
    "    ]\n",
    "    for image_file, label_file, landmark_file in zip(image_files, label_files,\n",
    "                                                     landmark_files):\n",
    "      with tf.io.gfile.GFile(label_file, \"rb\") as f:\n",
    "        mat = tfds.core.lazy_imports.scipy.io.loadmat(f)\n",
    "      pt2d_origin = mat[\"pt2d\"].T\n",
    "      pt2d_origin = (pt2d_origin / 450.0).astype(np.float32)\n",
    "      roi = mat[\"roi\"].reshape(4).astype(np.float32)\n",
    "      illum_params = mat[\"Illum_Para\"].reshape([-1]).astype(np.float32)\n",
    "      color_params = mat[\"Color_Para\"].reshape([-1]).astype(np.float32)\n",
    "      tex_params = mat[\"Tex_Para\"].reshape([-1]).astype(np.float32)\n",
    "      shape_params = mat[\"Shape_Para\"].reshape([-1]).astype(np.float32)\n",
    "      exp_params = mat[\"Exp_Para\"].reshape([-1]).astype(np.float32)\n",
    "      pose_params = mat[\"Pose_Para\"].reshape([-1]).astype(np.float32)\n",
    "      with tf.io.gfile.GFile(landmark_file, \"rb\") as f:\n",
    "        ldm_mat = tfds.core.lazy_imports.scipy.io.loadmat(f)\n",
    "        pt2d = (ldm_mat[\"pts_2d\"] / 450.0).astype(np.float32)\n",
    "        pt3d = (ldm_mat[\"pts_3d\"] / 450.0).astype(np.float32)\n",
    "      record = {\n",
    "          \"image\": image_file,\n",
    "          \"landmarks_origin\": pt2d_origin,\n",
    "          \"landmarks_2d\": pt2d,\n",
    "          \"landmarks_3d\": pt3d,\n",
    "          \"roi\": roi,\n",
    "          \"illum_params\": illum_params,\n",
    "          \"color_params\": color_params,\n",
    "          \"tex_params\": tex_params,\n",
    "          \"shape_params\": shape_params,\n",
    "          \"exp_params\": exp_params,\n",
    "          \"pose_params\": pose_params\n",
    "      }\n",
    "      yield os.path.basename(image_file), record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0be4e4dd-9174-4852-a40f-7f106ad61a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_examples(image_dir_path):\n",
    "    \"\"\"Yields examples.\"\"\"\n",
    "    image_files = tf.io.gfile.glob(\n",
    "        pattern=os.path.join(image_dir_path, \"[!Code]*[!_Flip]/[!_]*.jpg\"))\n",
    "    label_files = [s.replace(\"jpg\", \"mat\") for s in image_files]\n",
    "    landmark_files = [\n",
    "        s.replace(\"300W_LP\", \"300W_LP/landmarks\").replace(\".jpg\", \"_pts.mat\")\n",
    "        for s in image_files\n",
    "    ]\n",
    "    print(image_files,label_files,landmark_files)\n",
    "    for image_file, label_file, landmark_file in zip(image_files, label_files,\n",
    "                                                     landmark_files):\n",
    "        with tf.io.gfile.GFile(label_file, \"rb\") as f:\n",
    "            mat = tfds.core.lazy_imports.scipy.io.loadmat(f)\n",
    "        pt2d_origin = mat[\"pt2d\"].T\n",
    "        pt2d_origin = (pt2d_origin / 450.0).astype(np.float32)\n",
    "        roi = mat[\"roi\"].reshape(4).astype(np.float32)\n",
    "        illum_params = mat[\"Illum_Para\"].reshape([-1]).astype(np.float32)\n",
    "        color_params = mat[\"Color_Para\"].reshape([-1]).astype(np.float32)\n",
    "        tex_params = mat[\"Tex_Para\"].reshape([-1]).astype(np.float32)\n",
    "        shape_params = mat[\"Shape_Para\"].reshape([-1]).astype(np.float32)\n",
    "        exp_params = mat[\"Exp_Para\"].reshape([-1]).astype(np.float32)\n",
    "        pose_params = mat[\"Pose_Para\"].reshape([-1]).astype(np.float32)\n",
    "        with tf.io.gfile.GFile(landmark_file, \"rb\") as f:\n",
    "            ldm_mat = tfds.core.lazy_imports.scipy.io.loadmat(f)\n",
    "            pt2d = (ldm_mat[\"pts_2d\"] / 450.0).astype(np.float32)\n",
    "            pt3d = (ldm_mat[\"pts_3d\"] / 450.0).astype(np.float32)\n",
    "        record = {\n",
    "          \"image\": image_file,\n",
    "          \"landmarks_origin\": pt2d_origin,\n",
    "          \"landmarks_2d\": pt2d,\n",
    "          \"landmarks_3d\": pt3d,\n",
    "          \"roi\": roi,\n",
    "          \"illum_params\": illum_params,\n",
    "          \"color_params\": color_params,\n",
    "          \"tex_params\": tex_params,\n",
    "          \"shape_params\": shape_params,\n",
    "          \"exp_params\": exp_params,\n",
    "          \"pose_params\": pose_params\n",
    "        }\n",
    "        return os.path.basename(image_file), record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1191ea7e-b24f-43bf-b014-ff2259c6317e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] [] []\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(generate_examples(\"data/AFW/AFW_1051618982_1_0.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e29815a-8f49-42f3-8372-e265f1f7231b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
